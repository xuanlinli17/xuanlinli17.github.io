I"<p>We study how choices of input point cloud coordinate frames affect learning of manipulation skills from 3D point clouds. There exist a variety of coordinate frame choices to normalize captured robot-object-interaction point clouds. We find that different frames have a profound impact on agent learning performance, and the trend is similar across 3D backbone networks. In particular, the end-effector frame
6 and the target-part frame achieve higher training efficiency than the commonly
7 used world frame and robot-base frame in many tasks, intuitively because they
8 provide helpful alignments among point clouds across time steps and thus can sim9 plify visual module learning. Moreover, the well-performing frames vary across
10 tasks, and some tasks may benefit from multiple frame candidates. We thus pro11 pose FrameMiners to adaptively select candidate frames and fuse their merits in
12 a task-agnostic manner. Experimentally, FrameMiners achieves on-par or signifi13 cantly higher performance than the best single-frame version on five fully physical
14 manipulation tasks adapted from ManiSkill and OCRTOC. Without changing ex15 isting camera placements or adding extra cameras, point cloud frame mining can
16 serve as a free lunch to improve 3D manipulation learning.</p>
:ET